{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v3 import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "                  \n",
    "    parameters = {\n",
    "        \"W1\":W1,\n",
    "        \"b1\":b1,\n",
    "        \"W2\":W2,\n",
    "        \"b2\":b2\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01624345, -0.00611756, -0.00528172],\n",
       "        [-0.01072969,  0.00865408, -0.02301539]]), 'b1': array([[0.],\n",
       "        [0.]]), 'W2': array([[ 0.01744812, -0.00761207]]), 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = initialize_parameters(3,2,1)\n",
    "parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters[\"W\" + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 0.00319039, -0.0024937 ,  0.01462108, -0.02060141, -0.00322417],\n",
      "       [-0.00384054,  0.01133769, -0.01099891, -0.00172428, -0.00877858],\n",
      "       [ 0.00042214,  0.00582815, -0.01100619,  0.01144724,  0.00901591],\n",
      "       [ 0.00502494,  0.00900856, -0.00683728, -0.0012289 , -0.00935769]]), 'b1': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'W2': array([[-0.00267888,  0.00530355, -0.00691661, -0.00396754],\n",
      "       [-0.00687173, -0.00845206, -0.00671246, -0.00012665],\n",
      "       [-0.0111731 ,  0.00234416,  0.01659802,  0.00742044]]), 'b2': array([[0.],\n",
      "       [0.],\n",
      "       [0.]])}\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    \n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.26295337 -1.23429987]]\n",
      "(array([[ 1.62434536, -0.61175641],\n",
      "       [-0.52817175, -1.07296862],\n",
      "       [ 0.86540763, -2.3015387 ]]), array([[ 1.74481176, -0.7612069 ,  0.3190391 ]]), array([[-0.24937038]]))\n"
     ]
    }
   ],
   "source": [
    "A, W, b = linear_forward_test_case()\n",
    "Z, cache = linear_forward(A, W, b)\n",
    "print(Z)\n",
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward_activation(A_pre, W, b, activation):\n",
    "    \n",
    "    Z, linear_cache = linear_forward(A_pre, W, b)\n",
    "    if activation == 'sigmoid':\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == 'relu':\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert(A.shape == (W.shape[0], A_pre.shape[1]))    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96890023 0.11013289]]\n",
      "[[3.43896131 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A_pre, W, b = linear_activation_forward_test_case()\n",
    "\n",
    "A, cache = linear_forward_activation(A_pre, W, b, 'sigmoid')\n",
    "print(A)\n",
    "\n",
    "A, cache = linear_forward_activation(A_pre, W, b, 'relu')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_pre = A\n",
    "        A, cache = linear_forward_activation(A_pre, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_forward_activation(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1, X.shape[1]))\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.03921668 0.70498921 0.19734387 0.04728177]]\n",
      "Length of caches list = 3\n"
     ]
    }
   ],
   "source": [
    "X, parameters = L_model_forward_test_case_2hidden()\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    cost = -np.sum(np.multiply(np.log(AL),Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.414931599615397\n"
     ]
    }
   ],
   "source": [
    "Y, AL = compute_cost_test_case()\n",
    "\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev = [[ 0.51822968 -0.19517421]\n",
      " [-0.40506361  0.15255393]\n",
      " [ 2.37496825 -0.89445391]]\n",
      "dW = [[-0.10076895  1.40685096  1.64992505]]\n",
      "db = [[0.50629448]]\n"
     ]
    }
   ],
   "source": [
    "# Set up some test inputs\n",
    "dZ, linear_cache = linear_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:\n",
      "dA_prev = [[ 0.11017994  0.01105339]\n",
      " [ 0.09466817  0.00949723]\n",
      " [-0.05743092 -0.00576154]]\n",
      "dW = [[ 0.10266786  0.09778551 -0.01968084]]\n",
      "db = [[-0.05729622]]\n",
      "\n",
      "relu:\n",
      "dA_prev = [[ 0.44090989 -0.        ]\n",
      " [ 0.37883606 -0.        ]\n",
      " [-0.2298228   0.        ]]\n",
      "dW = [[ 0.44513824  0.37371418 -0.10478989]]\n",
      "db = [[-0.20837892]]\n"
     ]
    }
   ],
   "source": [
    "AL, linear_activation_cache = linear_activation_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print (\"sigmoid:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db) + \"\\n\")\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = \"relu\")\n",
    "print (\"relu:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \n",
    "    grads ={}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads['dA' + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dA2': array([[ 0.12913162, -0.44014127],\n",
       "        [-0.14175655,  0.48317296],\n",
       "        [ 0.01663708, -0.05670698]]),\n",
       " 'dW2': array([[-0.39202432, -0.13325855, -0.04601089]]),\n",
       " 'db2': array([[0.15187861]]),\n",
       " 'dA1': array([[ 0.        ,  0.52257901],\n",
       "        [ 0.        , -0.3269206 ],\n",
       "        [ 0.        , -0.32070404],\n",
       "        [ 0.        , -0.74079187]]),\n",
       " 'dW1': array([[0.41010002, 0.07807203, 0.13798444, 0.10502167],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.05283652, 0.01005865, 0.01777766, 0.0135308 ]]),\n",
       " 'db1': array([[-0.22007063],\n",
       "        [ 0.        ],\n",
       "        [-0.02835349]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = L_model_backward(AL, Y_assess, caches)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.59562069, -0.09991781, -2.14584584,  1.82662008],\n",
       "        [-1.76569676, -0.80627147,  0.51115557, -1.18258802],\n",
       "        [-1.0535704 , -0.86128581,  0.68284052,  2.20374577]]),\n",
       " 'b1': array([[-0.04659241],\n",
       "        [-1.28888275],\n",
       "        [ 0.53405496]]),\n",
       " 'W2': array([[-0.55569196,  0.0354055 ,  1.32964895]]),\n",
       " 'b2': array([[-0.84610769]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearset'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Illegal interpolation string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b8f4126a6044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_orig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"y = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\". It's a \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m\" picture.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2701\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5490\u001b[0m         im = mimage.AxesImage(self, cmap, norm, interpolation, origin, extent,\n\u001b[0;32m   5491\u001b[0m                               \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5492\u001b[1;33m                               resample=resample, **kwargs)\n\u001b[0m\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5494\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m             \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         )\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_filternorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_filterrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_interpolation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\APP\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_interpolation\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_interpd_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Illegal interpolation string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Illegal interpolation string"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
